---
layout: post
title:  "并发处理安全问题"
date:   2015-05-19 20:36:36
categories: share
---

在进行业务开发时，通常都会或多或少的遇到并发处理场景，一些简单的逻辑可能在并发场景下会变得复杂些，简单整理下遇到的几个小坑。

### case 1
积分墙有一个回调模块，大致逻辑是从数据库里取出来处理成功的订单，回调给媒体。这是一个典型的使用生产者消费者模式处理的场景。
在程序中，我们启动两个子线程，一个线程负责生产，将数据库中处理成功的订单记录取出来，例如status标记为5的订单，放入queue中；
另一个线程负责消费，从queue中获取数据处理，并且标记为回调成功，例如将status标记为6。    

程序启动后看起来是没有什么问题，当消费者的速度大于生产者时，的确不会出现什么问题。可是当消费者的速度比生产者慢时，问题出现了，
生产者第一次的数据放入queue中，消费者还没消费完的时候，生产者再一次去数据库里取数据，这样，由于queue中剩余的订单状态还没被标记为6，
导致这些订单又一次被取了出来，这样就发生订单的重复处理。    

如果生产者在把订单放入queue的时候就把订单的status置为6，也不会出现订单重复处理的问题，不过这样却带来了订单处理遗漏的问题，当程序被kill掉或异常退出时，
如果queue中还有数据，内存中的数据便丢失了，下载重启服务的时候，这些订单也不会被生产者重新放入queue中。    

我们通常使用的处理方式是使用python Queue的join()和task_done()函数来保证订单不会重复处理也不会遗漏，生产者将订单放入queue之后调用queue.join()，
这时如果queue中有n条记录，生产者线程会阻塞住，而当消费者每次取出一个订单处理后，调用queue.task_done()，当task_done()的调用n次时，
生产者不再阻塞，再一次去数据库中取数据，如此反复，这样生产者即不会取出重复的订单，程序异常退出时也不会有订单遗漏。

	#生产线程
	while True:
        dt = datetime.today() - timedelta(days=2)
        django.db.close_old_connections()
        transactions = TransactionHistory.objects.filter(
            # 根据订单状态取数据
            status = 5,
            dt__gt = int(dt.strftime("%Y%m%d")),
        )
        for trans in transactions:
            self.queue.put(trans)
        self.queue.join()
        # 一个小时查一次
        time.sleep(5*60)
            
    #消费线程
    while True:
        try:
            transaction = self.queue.get()
			# 业务逻辑
			........
        except Exception, e:
            self.logger.exception(e)
        finally:
            self.queue.task_done()

如果queue支持去重的话，其实我们也不用考虑这么多内容，不过没有特别关注有没有相关的实现。

### case 2
第二个场景很常见，如果做电商网站，可能会听过“超卖问题”。比如支付宝转账吧，转账时一定会判断你的账户里的钱是否足够转账，
足够的话再进行其他校验，最后再进行转账，从你的账户中扣除转出的金额，加到别人的账户中。考虑并发的场景，假设你同一个时间中发了两个兑换申请，
这样支付宝服务端同时收到两个请求，假设服务端是php吧，这样两个php进程就开始进行校验逻辑了，校验余额肯定是要先取出余额，
两个进程在同一时间去数据库中取数据，取到的余额是一样的，都是1000，你的转账金额是600，那么问题来了，两个进程同时进行余额校验时，
发现余额是1000，而转账600显然是足够的，接着去进行其他的校验，转账。最终两次转账都成功了，而你的账户余额变成了-200。    

这个问题也很典型，相似业务逻辑在代码实现时没有考虑到这点，平时可能很难发生异常，随着用户量越来越大，便开始出现异常的数据了。
特别是服务端处理逻辑需要开启事务时，默认情况下，在一个事务处理还没提交的时候，其他事务取出的数据，是不会受第一个事务的处理影响的。
这里我们使用的解决方式，是使用mysql提供的select ... for update语句。

InnoDB支持[select ... for update][mysql]来锁住行，使用时需要指定索引。它会阻塞其他select ... for update请求，普通的read操作则不会阻塞，
这样同一时间只用有一个执行select ... for update的事务能够取到数据，其他事务的查询请求阻塞直到当前事务提交。应用在上面提到的场景中，
当两个转账申请同时到来时，其中一条请求查询到余额后，另一个请求在查询余额时就被阻塞住了，直到第一个请求的处理事务commit，
第二个事务才能够拿到用户的余额，这样就避免了超卖问题。

	// 开启事务
	tx, err := db.Begin()
	if err != nil {
		return false
	}
	// 查询积分，使用select ... for update
	var point int
	err = tx.QueryRow(`select point from user_point where id = ? for update`, uid).Scan(&point)
	if err != nil {
		tx.Rollback()
		return false
	}
	// 判断积分是否足够
	if point < consume {
		tx.Rollback()
		return false
	}
	// 消耗积分
	_, err = tx.Exec(`update user_point set point = point - ?`, consume)
	if err != nil {
		tx.Rollback()
		return false
	}
	// 提交事务
	tx.Commit()
	return true

也可以在业务逻辑层，使用异步的方式来处理，转账请求先入队列，在从队列中取请求按顺序逐个进行，来保证同时只有一个请求在处理。
利用数据库事务的来处理效率会更高些，也很容易理解。

[mysql]:https://dev.mysql.com/doc/refman/5.0/en/innodb-locking-reads.html
